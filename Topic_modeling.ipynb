{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SmirthikaR/Topic-Modelling/blob/main/Topic_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6Ppt_pKerPV"
      },
      "outputs": [],
      "source": [
        "#creating a document\n",
        "d1=\"Dams control water flow\"\n",
        "d2=\"Dams create reservoirs\"\n",
        "d3=\"Building dams requires significant engineering\"\n",
        "d4=\"Dams provide irrigation for agriculture\"\n",
        "#creating corpus\n",
        "c=[d1,d2,d3,d4]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "# remove stopwords, punctuation, and normalize the corpus\n",
        "stop = set(stopwords.words('english'))\n",
        "exclude = set(string.punctuation)\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "def clean(doc):\n",
        "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
        "    punc_free = \"\".join(ch for ch in stop_free if ch not in exclude)\n",
        "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
        "    return normalized\n",
        "\n",
        "clean_corpus = [clean(doc).split() for doc in c]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBwVkimbfook",
        "outputId": "17de9057-ee12-4fb4-ea6b-f17d1ad98cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "\n",
        "# Creating document-term matrix\n",
        "dictionary = corpora.Dictionary(clean_corpus)\n",
        "doc_term_matrix = [dictionary.doc2bow(doc) for doc in clean_corpus]\n",
        "doc_term_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D54McmjfyTm",
        "outputId": "7f76d8be-3aaa-4f62-f633-528ad8142736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1), (1, 1), (2, 1), (3, 1)],\n",
              " [(1, 1), (4, 1), (5, 1)],\n",
              " [(1, 1), (6, 1), (7, 1), (8, 1), (9, 1)],\n",
              " [(1, 1), (10, 1), (11, 1), (12, 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1), (1, 1), (2, 1), (3, 1)],\n",
              " [(1, 1), (4, 1), (5, 1)],\n",
              " [(1, 1), (6, 1), (7, 1), (8, 1), (9, 1)],\n",
              " [(1, 1), (10, 1), (11, 1), (12, 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import LsiModel\n",
        "\n",
        "# LSA model\n",
        "lsa = LsiModel(doc_term_matrix, num_topics=4, id2word = dictionary)\n",
        "\n",
        "# LSA model\n",
        "print(lsa.print_topics(num_topics=4, num_words=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDa5MAClgYLX",
        "outputId": "a601c2aa-97fa-436f-b009-4b8ee1af8561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '0.738*\"dam\" + 0.236*\"requires\" + 0.236*\"engineering\"'), (1, '-0.402*\"significant\" + -0.402*\"engineering\" + -0.402*\"requires\"'), (2, '0.408*\"agriculture\" + 0.408*\"irrigation\" + 0.408*\"provide\"'), (3, '-0.607*\"reservoir\" + -0.607*\"create\" + 0.190*\"water\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import LdaModel\n",
        "\n",
        "# LDA model\n",
        "lda = LdaModel(doc_term_matrix, num_topics=3, id2word = dictionary)\n",
        "\n",
        "# Results\n",
        "print(lda.print_topics(num_topics=3, num_words=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04shM935gdHi",
        "outputId": "6669cebd-2716-4260-a160-eb83388e2b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '0.192*\"dam\" + 0.081*\"engineering\" + 0.081*\"significant\"'), (1, '0.183*\"dam\" + 0.155*\"create\" + 0.154*\"reservoir\"'), (2, '0.088*\"dam\" + 0.079*\"reservoir\" + 0.078*\"building\"')]\n"
          ]
        }
      ]
    }
  ]
}